{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# NBA Spread Prediction Pipeline\n",
        "\n",
        "**Production-ready blueprint for predicting NBA point spreads and ATS (Against The Spread) outcomes**\n",
        "\n",
        "## Goal\n",
        "- Predict the **point spread outcome** (expected margin = home_score - away_score)\n",
        "- Predict **cover/no-cover** vs the betting spread\n",
        "- Primary label: `margin_real = home_score - away_score`\n",
        "- Derived label: `residual = margin_real - closing_spread` (positive => home covers)\n",
        "\n",
        "## Pipeline Overview\n",
        "1. Data Loading & Integration\n",
        "2. Feature Engineering (ELO, recent form, rest days, injuries, market features)\n",
        "3. Model Training (Baseline → Linear → LightGBM)\n",
        "4. Time-Series Cross-Validation & Backtesting\n",
        "5. Model Evaluation & Interpretation\n",
        "6. Prediction Generation\n",
        "7. Deployment-Ready Code\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Core dependencies\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Modeling\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from sklearn.linear_model import Ridge, Lasso\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import lightgbm as lgb\n",
        "from joblib import dump, load\n",
        "\n",
        "# Visualization & interpretability\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "try:\n",
        "    import shap\n",
        "    SHAP_AVAILABLE = True\n",
        "except ImportError:\n",
        "    SHAP_AVAILABLE = False\n",
        "    print(\"SHAP not available. Install with: pip install shap\")\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "print(\"✓ Libraries loaded successfully\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 1: Data Loading & Integration\n",
        "\n",
        "Load data from the collection notebook or from saved CSV files.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_game_data(file_path: str = None) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Load game data from CSV or use data from collection notebook\n",
        "    \"\"\"\n",
        "    if file_path:\n",
        "        df = pd.read_csv(file_path, parse_dates=['date'])\n",
        "    else:\n",
        "        # Try to load from collection notebook output (check multiple possible files)\n",
        "        for filename in ['nba_games.csv', 'nba_games_test.csv']:\n",
        "            try:\n",
        "                df = pd.read_csv(filename, parse_dates=['date'])\n",
        "                print(f\"✓ Loaded data from {filename}\")\n",
        "                break\n",
        "            except FileNotFoundError:\n",
        "                continue\n",
        "        else:\n",
        "            print(\"⚠️  No game data file found. Run the data collection notebook first.\")\n",
        "            print(\"   Or provide a CSV with columns: game_id, date, home_team_id, away_team_id,\")\n",
        "            print(\"   home_score, away_score, home_team_name, away_team_name\")\n",
        "            return pd.DataFrame()\n",
        "    \n",
        "    # Ensure required columns exist\n",
        "    required_cols = ['date', 'home_team_id', 'away_team_id', 'home_score', 'away_score']\n",
        "    missing = [c for c in required_cols if c not in df.columns]\n",
        "    if missing:\n",
        "        print(f\"⚠️  Missing required columns: {missing}\")\n",
        "        return pd.DataFrame()\n",
        "    \n",
        "    df = df.sort_values('date').reset_index(drop=True)\n",
        "    df['margin'] = df['home_score'] - df['away_score']\n",
        "    \n",
        "    return df\n",
        "\n",
        "# Load data (modify path as needed)\n",
        "games_df = load_game_data()\n",
        "\n",
        "if len(games_df) > 0:\n",
        "    print(f\"✓ Loaded {len(games_df)} games\")\n",
        "    print(f\"  Date range: {games_df['date'].min()} to {games_df['date'].max()}\")\n",
        "    print(f\"\\nSample data:\")\n",
        "    print(games_df[['date', 'home_team_name', 'away_team_name', 'home_score', 'away_score', 'margin']].head())\n",
        "else:\n",
        "    print(\"⚠️  No data loaded. Please run data collection first or provide data file.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 2: Feature Engineering\n",
        "\n",
        "This is the heart of the model. We'll create features at multiple granularities.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ELORating:\n",
        "    \"\"\"\n",
        "    Simple ELO rating system for NBA teams\n",
        "    Updates after each game using the result\n",
        "    \"\"\"\n",
        "    def __init__(self, initial_rating=1500, k_factor=20):\n",
        "        self.initial_rating = initial_rating\n",
        "        self.k_factor = k_factor\n",
        "        self.ratings = {}\n",
        "    \n",
        "    def get_rating(self, team_id, date=None):\n",
        "        \"\"\"Get team rating at a specific date (or current if date=None)\"\"\"\n",
        "        if team_id not in self.ratings:\n",
        "            return self.initial_rating\n",
        "        if date is None:\n",
        "            return self.ratings[team_id][-1][1]  # Latest rating\n",
        "        # Find rating at or before date\n",
        "        for d, rating in reversed(self.ratings[team_id]):\n",
        "            if d <= date:\n",
        "                return rating\n",
        "        return self.initial_rating\n",
        "    \n",
        "    def update(self, team_id, opponent_id, margin, date, home_advantage=0):\n",
        "        \"\"\"\n",
        "        Update ELO after a game\n",
        "        margin = home_score - away_score (from home team's perspective)\n",
        "        \"\"\"\n",
        "        if team_id not in self.ratings:\n",
        "            self.ratings[team_id] = []\n",
        "        if opponent_id not in self.ratings:\n",
        "            self.ratings[opponent_id] = []\n",
        "        \n",
        "        # Get current ratings\n",
        "        team_rating = self.get_rating(team_id, date)\n",
        "        opp_rating = self.get_rating(opponent_id, date)\n",
        "        \n",
        "        # Expected score (sigmoid)\n",
        "        expected = 1 / (1 + 10 ** ((opp_rating - team_rating - home_advantage) / 400))\n",
        "        \n",
        "        # Actual score (normalize margin to 0-1 scale, capped)\n",
        "        # Margin of +10 = win by 10, treat as ~0.75 score\n",
        "        # Margin of -10 = loss by 10, treat as ~0.25 score\n",
        "        actual = 0.5 + np.clip(margin / 20, -0.5, 0.5)\n",
        "        \n",
        "        # Update ratings\n",
        "        new_team_rating = team_rating + self.k_factor * (actual - expected)\n",
        "        new_opp_rating = opp_rating + self.k_factor * (expected - actual)\n",
        "        \n",
        "        # Store with date\n",
        "        if not self.ratings[team_id] or self.ratings[team_id][-1][0] < date:\n",
        "            self.ratings[team_id].append((date, new_team_rating))\n",
        "        else:\n",
        "            self.ratings[team_id][-1] = (date, new_team_rating)\n",
        "            \n",
        "        if not self.ratings[opponent_id] or self.ratings[opponent_id][-1][0] < date:\n",
        "            self.ratings[opponent_id].append((date, new_opp_rating))\n",
        "        else:\n",
        "            self.ratings[opponent_id][-1] = (date, new_opp_rating)\n",
        "\n",
        "print(\"✓ ELO Rating class defined\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_rest_days(games_df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Calculate rest days for each team before each game\n",
        "    Returns DataFrame with rest_days_home and rest_days_away\n",
        "    \"\"\"\n",
        "    df = games_df.copy()\n",
        "    df['date'] = pd.to_datetime(df['date'])\n",
        "    df = df.sort_values('date').reset_index(drop=True)\n",
        "    \n",
        "    # Track last game date for each team\n",
        "    last_game_home = {}\n",
        "    last_game_away = {}\n",
        "    \n",
        "    rest_days_home = []\n",
        "    rest_days_away = []\n",
        "    is_back_to_back_home = []\n",
        "    is_back_to_back_away = []\n",
        "    \n",
        "    for idx, row in df.iterrows():\n",
        "        home_id = str(row['home_team_id'])\n",
        "        away_id = str(row['away_team_id'])\n",
        "        game_date = row['date']\n",
        "        \n",
        "        # Home team rest\n",
        "        if home_id in last_game_home:\n",
        "            rest = (game_date - last_game_home[home_id]).days\n",
        "            rest_days_home.append(rest)\n",
        "            is_back_to_back_home.append(rest == 0)\n",
        "        else:\n",
        "            rest_days_home.append(3)  # Default for first game\n",
        "            is_back_to_back_home.append(False)\n",
        "        \n",
        "        # Away team rest\n",
        "        if away_id in last_game_away:\n",
        "            rest = (game_date - last_game_away[away_id]).days\n",
        "            rest_days_away.append(rest)\n",
        "            is_back_to_back_away.append(rest == 0)\n",
        "        else:\n",
        "            rest_days_away.append(3)  # Default for first game\n",
        "            is_back_to_back_away.append(False)\n",
        "        \n",
        "        # Update last game dates (only after game is played)\n",
        "        # For forward-filling, we update immediately but use previous values for features\n",
        "        last_game_home[home_id] = game_date\n",
        "        last_game_away[away_id] = game_date\n",
        "    \n",
        "    df['rest_days_home'] = rest_days_home\n",
        "    df['rest_days_away'] = rest_days_away\n",
        "    df['rest_diff'] = df['rest_days_home'] - df['rest_days_away']\n",
        "    df['is_home_back_to_back'] = is_back_to_back_home\n",
        "    df['is_away_back_to_back'] = is_back_to_back_away\n",
        "    \n",
        "    return df\n",
        "\n",
        "print(\"✓ Rest days calculation function defined\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_rolling_features(games_df: pd.DataFrame, windows=[3, 5, 10]) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Calculate rolling window features for each team\n",
        "    Features: avg margin, avg points for, avg points against, std of margin\n",
        "    \"\"\"\n",
        "    df = games_df.copy()\n",
        "    df['date'] = pd.to_datetime(df['date'])\n",
        "    df = df.sort_values('date').reset_index(drop=True)\n",
        "    \n",
        "    # Initialize feature columns\n",
        "    for window in windows:\n",
        "        df[f'home_margin_avg_{window}'] = np.nan\n",
        "        df[f'away_margin_avg_{window}'] = np.nan\n",
        "        df[f'home_points_for_avg_{window}'] = np.nan\n",
        "        df[f'away_points_for_avg_{window}'] = np.nan\n",
        "        df[f'home_points_against_avg_{window}'] = np.nan\n",
        "        df[f'away_points_against_avg_{window}'] = np.nan\n",
        "        df[f'home_margin_std_{window}'] = np.nan\n",
        "        df[f'away_margin_std_{window}'] = np.nan\n",
        "    \n",
        "    # Track game history per team\n",
        "    team_history = {}\n",
        "    \n",
        "    for idx, row in df.iterrows():\n",
        "        home_id = str(row['home_team_id'])\n",
        "        away_id = str(row['away_team_id'])\n",
        "        game_date = row['date']\n",
        "        \n",
        "        # Initialize team history if needed\n",
        "        if home_id not in team_history:\n",
        "            team_history[home_id] = []\n",
        "        if away_id not in team_history:\n",
        "            team_history[away_id] = []\n",
        "        \n",
        "        # Calculate rolling features for home team (using past games only)\n",
        "        home_past_games = [g for g in team_history[home_id] if g['date'] < game_date]\n",
        "        if len(home_past_games) > 0:\n",
        "            home_margins = [g['margin'] for g in home_past_games]\n",
        "            home_scores = [g['score'] for g in home_past_games]\n",
        "            home_opp_scores = [g['opp_score'] for g in home_past_games]\n",
        "            \n",
        "            for window in windows:\n",
        "                if len(home_past_games) >= window:\n",
        "                    recent = home_past_games[-window:]\n",
        "                    recent_margins = [g['margin'] for g in recent]\n",
        "                    recent_scores = [g['score'] for g in recent]\n",
        "                    recent_opp_scores = [g['opp_score'] for g in recent]\n",
        "                    \n",
        "                    df.loc[idx, f'home_margin_avg_{window}'] = np.mean(recent_margins)\n",
        "                    df.loc[idx, f'home_points_for_avg_{window}'] = np.mean(recent_scores)\n",
        "                    df.loc[idx, f'home_points_against_avg_{window}'] = np.mean(recent_opp_scores)\n",
        "                    df.loc[idx, f'home_margin_std_{window}'] = np.std(recent_margins) if len(recent_margins) > 1 else 0\n",
        "        \n",
        "        # Calculate rolling features for away team\n",
        "        away_past_games = [g for g in team_history[away_id] if g['date'] < game_date]\n",
        "        if len(away_past_games) > 0:\n",
        "            for window in windows:\n",
        "                if len(away_past_games) >= window:\n",
        "                    recent = away_past_games[-window:]\n",
        "                    # For away team, margin is negative of their perspective\n",
        "                    recent_margins = [-g['margin'] for g in recent]  # Flip perspective\n",
        "                    recent_scores = [g['opp_score'] for g in recent]  # They were away, so opp_score is their score\n",
        "                    recent_opp_scores = [g['score'] for g in recent]\n",
        "                    \n",
        "                    df.loc[idx, f'away_margin_avg_{window}'] = np.mean(recent_margins)\n",
        "                    df.loc[idx, f'away_points_for_avg_{window}'] = np.mean(recent_scores)\n",
        "                    df.loc[idx, f'away_points_against_avg_{window}'] = np.mean(recent_opp_scores)\n",
        "                    df.loc[idx, f'away_margin_std_{window}'] = np.std(recent_margins) if len(recent_margins) > 1 else 0\n",
        "        \n",
        "        # Update team history AFTER calculating features (to avoid data leakage)\n",
        "        # Store from home team's perspective\n",
        "        team_history[home_id].append({\n",
        "            'date': game_date,\n",
        "            'margin': row['margin'],\n",
        "            'score': row['home_score'],\n",
        "            'opp_score': row['away_score']\n",
        "        })\n",
        "        # Store from away team's perspective (they were away)\n",
        "        team_history[away_id].append({\n",
        "            'date': game_date,\n",
        "            'margin': -row['margin'],  # Negative from their perspective\n",
        "            'score': row['away_score'],\n",
        "            'opp_score': row['home_score']\n",
        "        })\n",
        "    \n",
        "    return df\n",
        "\n",
        "print(\"✓ Rolling features calculation function defined\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_features(games_df: pd.DataFrame, elo: ELORating = None, include_spread: bool = True, include_injuries: bool = True) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Main feature engineering function\n",
        "    Combines all feature types into a single DataFrame\n",
        "    \"\"\"\n",
        "    if len(games_df) == 0:\n",
        "        return pd.DataFrame()\n",
        "    \n",
        "    df = games_df.copy()\n",
        "    df['date'] = pd.to_datetime(df['date'])\n",
        "    df = df.sort_values('date').reset_index(drop=True)\n",
        "    \n",
        "    # Filter to completed games with scores\n",
        "    df = df[(df['home_score'].notna()) & (df['away_score'].notna())].copy()\n",
        "    \n",
        "    if len(df) == 0:\n",
        "        return pd.DataFrame()\n",
        "    \n",
        "    # 1. Calculate rest days\n",
        "    df = calculate_rest_days(df)\n",
        "    \n",
        "    # 2. Calculate rolling features\n",
        "    df = calculate_rolling_features(df, windows=[3, 5, 10])\n",
        "    \n",
        "    # 3. ELO ratings (if provided)\n",
        "    if elo is None:\n",
        "        # Initialize and build ELO from scratch\n",
        "        elo = ELORating()\n",
        "        for idx, row in df.iterrows():\n",
        "            home_id = str(row['home_team_id'])\n",
        "            away_id = str(row['away_team_id'])\n",
        "            margin = row['margin']\n",
        "            game_date = row['date']\n",
        "            # Get ELO before this game (forward-fill)\n",
        "            home_elo = elo.get_rating(home_id, game_date)\n",
        "            away_elo = elo.get_rating(away_id, game_date)\n",
        "            # Update after game\n",
        "            elo.update(home_id, away_id, margin, game_date, home_advantage=70)  # ~3.5 point home advantage\n",
        "    \n",
        "    # Add ELO features (using ratings BEFORE each game)\n",
        "    elo_home_list = []\n",
        "    elo_away_list = []\n",
        "    for idx, row in df.iterrows():\n",
        "        home_id = str(row['home_team_id'])\n",
        "        away_id = str(row['away_team_id'])\n",
        "        game_date = row['date']\n",
        "        # Get rating just before this game\n",
        "        elo_home_list.append(elo.get_rating(home_id, game_date - timedelta(days=1)))\n",
        "        elo_away_list.append(elo.get_rating(away_id, game_date - timedelta(days=1)))\n",
        "    \n",
        "    df['elo_home'] = elo_home_list\n",
        "    df['elo_away'] = elo_away_list\n",
        "    df['elo_diff'] = df['elo_home'] - df['elo_away']\n",
        "    \n",
        "    # 4. Home court advantage (binary)\n",
        "    df['home_court'] = 1  # All games in our data are home/away (not neutral)\n",
        "    \n",
        "    # 5. Temporal features\n",
        "    df['day_of_week'] = df['date'].dt.dayofweek\n",
        "    df['month'] = df['date'].dt.month\n",
        "    df['is_weekend'] = (df['day_of_week'] >= 5).astype(int)\n",
        "    \n",
        "    # 6. Injury features (if available and enabled)\n",
        "    if include_injuries:\n",
        "        injury_cols = [c for c in df.columns if any(x in c for x in [\n",
        "            'injury', 'players_out', 'star_out', 'players_dtd'\n",
        "        ])]\n",
        "        if injury_cols:\n",
        "            print(f\"✓ Using {len(injury_cols)} injury features from dataset\")\n",
        "            # Create injury interaction features\n",
        "            if 'injury_severity_diff' in df.columns:\n",
        "                df['injury_x_elo_diff'] = df['injury_severity_diff'] * df['elo_diff']\n",
        "                df['injury_beyond_spread'] = df['injury_severity_diff'] - (df.get('spread_move', 0) * 0.5)\n",
        "        else:\n",
        "            print(\"⚠️  No injury features found in dataset. Run add_injuries_to_pipeline.py first.\")\n",
        "            # Initialize with zeros\n",
        "            injury_cols_default = [\n",
        "                'players_out_home', 'players_out_away', 'players_dtd_home', 'players_dtd_away',\n",
        "                'injury_severity_home', 'injury_severity_away', 'star_out_home', 'star_out_away',\n",
        "                'total_injury_impact_home', 'total_injury_impact_away',\n",
        "                'injury_severity_diff', 'players_out_diff', 'total_injury_impact_diff'\n",
        "            ]\n",
        "            for col in injury_cols_default:\n",
        "                if col not in df.columns:\n",
        "                    df[col] = 0.0\n",
        "    \n",
        "    # 7. Interaction features\n",
        "    df['elo_diff_x_rest_diff'] = df['elo_diff'] * df['rest_diff']\n",
        "    df['home_margin_avg_5_x_elo_home'] = df['home_margin_avg_5'] * df['elo_home']\n",
        "    \n",
        "    # 8. Market features (if available)\n",
        "    if 'closing_spread' in df.columns:\n",
        "        df['closing_spread'] = df['closing_spread']\n",
        "    elif include_spread:\n",
        "        # Simulate closing spread as ELO-based estimate (for demo)\n",
        "        df['closing_spread'] = (df['elo_home'] - df['elo_away']) / 25  # Rough conversion\n",
        "        print(\"⚠️  No closing_spread column found. Using ELO-based estimate.\")\n",
        "    else:\n",
        "        df['closing_spread'] = 0\n",
        "    \n",
        "    if 'opening_spread' in df.columns:\n",
        "        df['spread_move'] = df['closing_spread'] - df['opening_spread']\n",
        "    else:\n",
        "        df['spread_move'] = 0\n",
        "    \n",
        "    # 9. Target variables\n",
        "    df['margin'] = df['home_score'] - df['away_score']\n",
        "    df['residual'] = df['margin'] - df['closing_spread']\n",
        "    df['cover'] = (df['residual'] > 0).astype(int)\n",
        "    \n",
        "    # 10. Fill NaN values in rolling features (early season games)\n",
        "    rolling_cols = [c for c in df.columns if any(x in c for x in ['avg_', 'std_'])]\n",
        "    for col in rolling_cols:\n",
        "        df[col] = df[col].fillna(0)\n",
        "    \n",
        "    return df\n",
        "\n",
        "print(\"✓ Feature engineering function defined\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 3: Build Feature Dataset\n",
        "\n",
        "Apply feature engineering to the game data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build features\n",
        "if len(games_df) > 0:\n",
        "    # Check if injury features exist in dataset\n",
        "    has_injuries = any('injury' in c.lower() or 'players_out' in c.lower() for c in games_df.columns)\n",
        "    \n",
        "    features_df = build_features(games_df, include_spread=True, include_injuries=has_injuries)\n",
        "    \n",
        "    if len(features_df) > 0:\n",
        "        print(f\"✓ Built features for {len(features_df)} games\")\n",
        "        \n",
        "        # Check for multicollinearity if injuries are present\n",
        "        injury_cols = [c for c in features_df.columns if any(x in c for x in ['injury', 'players_out', 'star_out'])]\n",
        "        spread_cols = [c for c in features_df.columns if 'spread' in c.lower() or 'elo_diff' in c]\n",
        "        \n",
        "        if injury_cols and spread_cols:\n",
        "            print(f\"\\n[Multicollinearity Check]\")\n",
        "            print(f\"  Injury features: {len(injury_cols)}\")\n",
        "            print(f\"  Spread-related features: {len(spread_cols)}\")\n",
        "            \n",
        "            # Calculate correlations\n",
        "            try:\n",
        "                from injury_features import analyze_injury_correlations, check_multicollinearity\n",
        "                corr_matrix = analyze_injury_correlations(features_df)\n",
        "                if not corr_matrix.empty:\n",
        "                    print(f\"\\n  Correlation Matrix (sample):\")\n",
        "                    print(corr_matrix.round(3).head())\n",
        "                    \n",
        "                    multicoll_results = check_multicollinearity(features_df, threshold=0.8)\n",
        "                    if multicoll_results['warnings']:\n",
        "                        print(f\"\\n  ⚠️  High correlations detected:\")\n",
        "                        for warning in multicoll_results['warnings'][:5]:  # Show first 5\n",
        "                            print(f\"    {warning}\")\n",
        "                    else:\n",
        "                        print(f\"\\n  ✓ No high correlations (threshold: 0.8)\")\n",
        "            except ImportError:\n",
        "                print(\"  (Multicollinearity analysis available via injury_features module)\")\n",
        "        \n",
        "        feature_cols = [c for c in features_df.columns if c not in [\n",
        "            'game_id', 'date', 'home_team_id', 'away_team_id', 'home_team_name', \n",
        "            'away_team_name', 'home_score', 'away_score', 'margin', 'residual', \n",
        "            'cover', 'closing_spread', 'opening_spread', 'spread_move', 'status',\n",
        "            'completed', 'venue', 'attendance', 'name', 'short_name'\n",
        "        ]]\n",
        "        print(f\"\\nTotal feature columns: {len(feature_cols)}\")\n",
        "        \n",
        "        print(f\"\\nSample features:\")\n",
        "        display_cols = ['date', 'home_team_name', 'away_team_name', 'elo_home', 'elo_away', \n",
        "                       'elo_diff', 'rest_diff', 'margin', 'closing_spread', 'residual']\n",
        "        if injury_cols:\n",
        "            display_cols.extend(['injury_severity_diff', 'players_out_diff'])\n",
        "        print(features_df[display_cols].head(10))\n",
        "    else:\n",
        "        print(\"⚠️  No features generated. Check data quality.\")\n",
        "else:\n",
        "    print(\"⚠️  No game data available. Please load data first.\")\n",
        "    features_df = pd.DataFrame()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 4: Model Training Pipeline\n",
        "\n",
        "Implement baseline → linear → LightGBM models with time-series cross-validation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def prepare_model_data(features_df: pd.DataFrame, target: str = 'residual'):\n",
        "    \"\"\"\n",
        "    Prepare data for modeling\n",
        "    Returns: X (features), y (target), feature_names, metadata\n",
        "    \"\"\"\n",
        "    if len(features_df) == 0:\n",
        "        return None, None, [], pd.DataFrame()\n",
        "    \n",
        "    # Exclude non-feature columns\n",
        "    exclude_cols = [\n",
        "        'game_id', 'date', 'home_team_id', 'away_team_id', 'home_team_name', \n",
        "        'away_team_name', 'home_score', 'away_score', 'margin', 'residual', \n",
        "        'cover', 'closing_spread', 'opening_spread', 'spread_move', 'status',\n",
        "        'completed', 'venue', 'attendance', 'name', 'short_name', 'point_differential'\n",
        "    ]\n",
        "    \n",
        "    feature_cols = [c for c in features_df.columns if c not in exclude_cols]\n",
        "    \n",
        "    # Remove any remaining non-numeric columns\n",
        "    numeric_cols = []\n",
        "    for col in feature_cols:\n",
        "        if features_df[col].dtype in [np.int64, np.float64, np.int32, np.float32]:\n",
        "            numeric_cols.append(col)\n",
        "        elif features_df[col].dtype == 'object':\n",
        "            # Try to convert\n",
        "            try:\n",
        "                features_df[col] = pd.to_numeric(features_df[col], errors='coerce')\n",
        "                numeric_cols.append(col)\n",
        "            except:\n",
        "                pass\n",
        "    \n",
        "    feature_cols = numeric_cols\n",
        "    \n",
        "    # Create feature matrix\n",
        "    X = features_df[feature_cols].fillna(0).values\n",
        "    y = features_df[target].values\n",
        "    \n",
        "    # Metadata for tracking\n",
        "    metadata = features_df[['date', 'home_team_name', 'away_team_name', 'margin', 'closing_spread', 'residual']].copy()\n",
        "    \n",
        "    return X, y, feature_cols, metadata\n",
        "\n",
        "print(\"✓ Data preparation function defined\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_model(y_true, y_pred, metadata=None, model_name=\"\"):\n",
        "    \"\"\"\n",
        "    Comprehensive model evaluation\n",
        "    \"\"\"\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "    r2 = r2_score(y_true, y_pred)\n",
        "    \n",
        "    # Betting-relevant metrics\n",
        "    if metadata is not None and 'closing_spread' in metadata.columns:\n",
        "        # Predicted margin = predicted residual + closing spread\n",
        "        pred_margin = y_pred + metadata['closing_spread'].values\n",
        "        true_margin = metadata['margin'].values\n",
        "        \n",
        "        # Cover prediction accuracy\n",
        "        pred_cover = (y_pred > 0).astype(int)\n",
        "        true_cover = (metadata['residual'].values > 0).astype(int)\n",
        "        cover_accuracy = (pred_cover == true_cover).mean()\n",
        "        \n",
        "        # Average edge\n",
        "        avg_edge = np.mean(y_pred - metadata['residual'].values)\n",
        "        \n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"{model_name} - Evaluation Metrics\")\n",
        "        print(f\"{'='*60}\")\n",
        "        print(f\"MAE (residual): {mae:.3f}\")\n",
        "        print(f\"RMSE (residual): {rmse:.3f}\")\n",
        "        print(f\"R² (residual): {r2:.3f}\")\n",
        "        print(f\"\\nBetting Metrics:\")\n",
        "        print(f\"Cover Accuracy: {cover_accuracy:.1%}\")\n",
        "        print(f\"Average Edge: {avg_edge:.3f}\")\n",
        "        print(f\"MAE (margin): {mean_absolute_error(true_margin, pred_margin):.3f}\")\n",
        "    else:\n",
        "        print(f\"\\n{model_name} - MAE: {mae:.3f}, RMSE: {rmse:.3f}, R²: {r2:.3f}\")\n",
        "    \n",
        "    return {\n",
        "        'mae': mae,\n",
        "        'rmse': rmse,\n",
        "        'r2': r2,\n",
        "        'cover_accuracy': cover_accuracy if metadata is not None else None,\n",
        "        'avg_edge': avg_edge if metadata is not None else None\n",
        "    }\n",
        "\n",
        "print(\"✓ Evaluation function defined\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model 1: Baseline (Closing Spread)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Baseline: predicted residual = 0 (i.e., margin = closing_spread)\n",
        "if len(features_df) > 0:\n",
        "    # Use closing spread as prediction (residual = 0)\n",
        "    baseline_pred = np.zeros(len(features_df))\n",
        "    baseline_metrics = evaluate_model(\n",
        "        features_df['residual'].values, \n",
        "        baseline_pred, \n",
        "        features_df,\n",
        "        \"Baseline (Closing Spread)\"\n",
        "    )\n",
        "else:\n",
        "    print(\"⚠️  No data available for baseline model\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model 2: Linear Model (Ridge Regression)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_linear_model(X_train, y_train, X_val, y_val, alpha=1.0):\n",
        "    \"\"\"\n",
        "    Train Ridge regression model\n",
        "    \"\"\"\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_val_scaled = scaler.transform(X_val)\n",
        "    \n",
        "    model = Ridge(alpha=alpha)\n",
        "    model.fit(X_train_scaled, y_train)\n",
        "    \n",
        "    pred_train = model.predict(X_train_scaled)\n",
        "    pred_val = model.predict(X_val_scaled)\n",
        "    \n",
        "    return model, scaler, pred_train, pred_val\n",
        "\n",
        "if len(features_df) > 0:\n",
        "    # Prepare data\n",
        "    X, y, feature_names, metadata = prepare_model_data(features_df, target='residual')\n",
        "    \n",
        "    if X is not None and len(X) > 100:\n",
        "        # Time-series split\n",
        "        tscv = TimeSeriesSplit(n_splits=3)\n",
        "        linear_maes = []\n",
        "        linear_models = []\n",
        "        \n",
        "        for train_idx, val_idx in tscv.split(X):\n",
        "            X_train, X_val = X[train_idx], X[val_idx]\n",
        "            y_train, y_val = y[train_idx], y[val_idx]\n",
        "            \n",
        "            model, scaler, _, pred_val = train_linear_model(X_train, y_train, X_val, y_val, alpha=1.0)\n",
        "            mae = mean_absolute_error(y_val, pred_val)\n",
        "            linear_maes.append(mae)\n",
        "            linear_models.append((model, scaler))\n",
        "        \n",
        "        print(f\"\\nLinear Model CV MAE: {np.mean(linear_maes):.3f} ± {np.std(linear_maes):.3f}\")\n",
        "        \n",
        "        # Retrain on full training set\n",
        "        final_linear_model, final_scaler = linear_models[-1]  # Use last fold's model\n",
        "        print(\"✓ Linear model trained\")\n",
        "    else:\n",
        "        print(\"⚠️  Insufficient data for linear model\")\n",
        "        final_linear_model, final_scaler = None, None\n",
        "else:\n",
        "    print(\"⚠️  No data available\")\n",
        "    final_linear_model, final_scaler = None, None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model 3: LightGBM (Main Model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_lightgbm(X_train, y_train, X_val, y_val, feature_names, params=None):\n",
        "    \"\"\"\n",
        "    Train LightGBM model with early stopping\n",
        "    \"\"\"\n",
        "    if params is None:\n",
        "        params = {\n",
        "            \"objective\": \"regression\",\n",
        "            \"metric\": \"mae\",\n",
        "            \"boosting_type\": \"gbdt\",\n",
        "            \"learning_rate\": 0.05,\n",
        "            \"num_leaves\": 31,\n",
        "            \"feature_fraction\": 0.8,\n",
        "            \"bagging_fraction\": 0.8,\n",
        "            \"bagging_freq\": 5,\n",
        "            \"min_child_samples\": 20,\n",
        "            \"verbose\": -1,\n",
        "            \"seed\": 42\n",
        "        }\n",
        "    \n",
        "    dtrain = lgb.Dataset(X_train, label=y_train, feature_name=feature_names)\n",
        "    dval = lgb.Dataset(X_val, label=y_val, reference=dtrain, feature_name=feature_names)\n",
        "    \n",
        "    model = lgb.train(\n",
        "        params,\n",
        "        dtrain,\n",
        "        num_boost_round=1000,\n",
        "        valid_sets=[dval],\n",
        "        valid_names=['val'],\n",
        "        callbacks=[lgb.early_stopping(stopping_rounds=50, verbose=False)]\n",
        "    )\n",
        "    \n",
        "    pred_train = model.predict(X_train, num_iteration=model.best_iteration)\n",
        "    pred_val = model.predict(X_val, num_iteration=model.best_iteration)\n",
        "    \n",
        "    return model, pred_train, pred_val\n",
        "\n",
        "if len(features_df) > 0 and X is not None and len(X) > 100:\n",
        "    # Time-series cross-validation for LightGBM\n",
        "    tscv = TimeSeriesSplit(n_splits=3)\n",
        "    lgb_maes = []\n",
        "    lgb_models = []\n",
        "    lgb_feature_importances = []\n",
        "    \n",
        "    for fold, (train_idx, val_idx) in enumerate(tscv.split(X)):\n",
        "        X_train, X_val = X[train_idx], X[val_idx]\n",
        "        y_train, y_val = y[train_idx], y[val_idx]\n",
        "        meta_val = metadata.iloc[val_idx]\n",
        "        \n",
        "        model, _, pred_val = train_lightgbm(X_train, y_train, X_val, y_val, feature_names)\n",
        "        \n",
        "        mae = mean_absolute_error(y_val, pred_val)\n",
        "        lgb_maes.append(mae)\n",
        "        lgb_models.append(model)\n",
        "        lgb_feature_importances.append(model.feature_importance(importance_type='gain'))\n",
        "        \n",
        "        print(f\"Fold {fold+1} MAE: {mae:.3f}\")\n",
        "    \n",
        "    print(f\"\\nLightGBM CV MAE: {np.mean(lgb_maes):.3f} ± {np.std(lgb_maes):.3f}\")\n",
        "    \n",
        "    # Retrain on full dataset\n",
        "    # Use average best iteration from CV\n",
        "    avg_best_iter = int(np.mean([m.best_iteration for m in lgb_models]))\n",
        "    \n",
        "    final_lgb_model = lgb.train(\n",
        "        {\n",
        "            \"objective\": \"regression\",\n",
        "            \"metric\": \"mae\",\n",
        "            \"boosting_type\": \"gbdt\",\n",
        "            \"learning_rate\": 0.05,\n",
        "            \"num_leaves\": 31,\n",
        "            \"feature_fraction\": 0.8,\n",
        "            \"bagging_fraction\": 0.8,\n",
        "            \"bagging_freq\": 5,\n",
        "            \"min_child_samples\": 20,\n",
        "            \"verbose\": -1,\n",
        "            \"seed\": 42\n",
        "        },\n",
        "        lgb.Dataset(X, label=y, feature_name=feature_names),\n",
        "        num_boost_round=avg_best_iter\n",
        "    )\n",
        "    \n",
        "    print(\"✓ LightGBM model trained\")\n",
        "    \n",
        "    # Feature importance\n",
        "    feature_importance_df = pd.DataFrame({\n",
        "        'feature': feature_names,\n",
        "        'importance': final_lgb_model.feature_importance(importance_type='gain')\n",
        "    }).sort_values('importance', ascending=False)\n",
        "    \n",
        "    print(f\"\\nTop 10 Most Important Features:\")\n",
        "    print(feature_importance_df.head(10))\n",
        "    \n",
        "else:\n",
        "    print(\"⚠️  Insufficient data for LightGBM\")\n",
        "    final_lgb_model = None\n",
        "    feature_importance_df = pd.DataFrame()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 5: Model Evaluation & Backtesting\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def walk_forward_backtest(features_df, model_func, min_train_games=200, test_size=50):\n",
        "    \"\"\"\n",
        "    Walk-forward backtesting: train on past, test on future\n",
        "    Simulates real-world deployment\n",
        "    \"\"\"\n",
        "    df = features_df.sort_values('date').reset_index(drop=True)\n",
        "    \n",
        "    results = []\n",
        "    test_predictions = []\n",
        "    \n",
        "    # Start testing after minimum training games\n",
        "    for test_start in range(min_train_games, len(df), test_size):\n",
        "        test_end = min(test_start + test_size, len(df))\n",
        "        \n",
        "        train = df.iloc[:test_start]\n",
        "        test = df.iloc[test_start:test_end]\n",
        "        \n",
        "        if len(test) == 0:\n",
        "            break\n",
        "        \n",
        "        # Prepare data\n",
        "        X_train, y_train, _, _ = prepare_model_data(train, target='residual')\n",
        "        X_test, y_test, _, meta_test = prepare_model_data(test, target='residual')\n",
        "        \n",
        "        if X_train is None or X_test is None or len(X_train) < 50:\n",
        "            continue\n",
        "        \n",
        "        # Train model\n",
        "        try:\n",
        "            model, _, _ = train_lightgbm(X_train, y_train, X_test, y_test, feature_names)\n",
        "            pred_test = model.predict(X_test, num_iteration=model.best_iteration)\n",
        "            \n",
        "            # Evaluate\n",
        "            mae = mean_absolute_error(y_test, pred_test)\n",
        "            rmse = np.sqrt(mean_squared_error(y_test, pred_test))\n",
        "            \n",
        "            # Betting metrics\n",
        "            pred_margin = pred_test + meta_test['closing_spread'].values\n",
        "            true_margin = meta_test['margin'].values\n",
        "            pred_cover = (pred_test > 0).astype(int)\n",
        "            true_cover = (meta_test['residual'].values > 0).astype(int)\n",
        "            cover_acc = (pred_cover == true_cover).mean()\n",
        "            \n",
        "            results.append({\n",
        "                'test_start': test_start,\n",
        "                'test_end': test_end,\n",
        "                'n_games': len(test),\n",
        "                'mae': mae,\n",
        "                'rmse': rmse,\n",
        "                'cover_accuracy': cover_acc\n",
        "            })\n",
        "            \n",
        "            # Store predictions\n",
        "            for idx, (_, row) in enumerate(meta_test.iterrows()):\n",
        "                test_predictions.append({\n",
        "                    'date': row['date'],\n",
        "                    'home_team': row['home_team_name'],\n",
        "                    'away_team': row['away_team_name'],\n",
        "                    'true_margin': row['margin'],\n",
        "                    'closing_spread': row['closing_spread'],\n",
        "                    'pred_residual': pred_test[idx],\n",
        "                    'pred_margin': pred_margin[idx],\n",
        "                    'true_cover': true_cover[idx],\n",
        "                    'pred_cover': pred_cover[idx]\n",
        "                })\n",
        "            \n",
        "            print(f\"Backtest window {test_start}-{test_end}: MAE={mae:.3f}, Cover Acc={cover_acc:.1%}\")\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"Error in backtest window {test_start}-{test_end}: {e}\")\n",
        "            continue\n",
        "    \n",
        "    return pd.DataFrame(results), pd.DataFrame(test_predictions)\n",
        "\n",
        "if len(features_df) > 200:\n",
        "    print(\"Running walk-forward backtest...\")\n",
        "    backtest_results, backtest_preds = walk_forward_backtest(features_df, train_lightgbm)\n",
        "    \n",
        "    if len(backtest_results) > 0:\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(\"Backtest Summary\")\n",
        "        print(f\"{'='*60}\")\n",
        "        print(f\"Total test windows: {len(backtest_results)}\")\n",
        "        print(f\"Average MAE: {backtest_results['mae'].mean():.3f}\")\n",
        "        print(f\"Average Cover Accuracy: {backtest_results['cover_accuracy'].mean():.1%}\")\n",
        "        print(f\"\\nBacktest Results DataFrame:\")\n",
        "        print(backtest_results)\n",
        "else:\n",
        "    print(\"⚠️  Insufficient data for backtesting (need >200 games)\")\n",
        "    backtest_results, backtest_preds = pd.DataFrame(), pd.DataFrame()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 6: Model Interpretation (SHAP)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if SHAP_AVAILABLE and final_lgb_model is not None and X is not None:\n",
        "    print(\"Computing SHAP values for model interpretation...\")\n",
        "    \n",
        "    # Use a sample for SHAP (it can be slow)\n",
        "    sample_size = min(100, len(X))\n",
        "    sample_idx = np.random.choice(len(X), sample_size, replace=False)\n",
        "    X_sample = X[sample_idx]\n",
        "    \n",
        "    explainer = shap.TreeExplainer(final_lgb_model)\n",
        "    shap_values = explainer.shap_values(X_sample)\n",
        "    \n",
        "    print(\"✓ SHAP values computed\")\n",
        "    print(\"\\nTo visualize SHAP plots, run:\")\n",
        "    print(\"  shap.summary_plot(shap_values, X_sample, feature_names=feature_names)\")\n",
        "    print(\"  shap.waterfall_plot(explainer.expected_value, shap_values[0], X_sample[0], feature_names=feature_names)\")\n",
        "else:\n",
        "    if not SHAP_AVAILABLE:\n",
        "        print(\"⚠️  SHAP not available. Install with: pip install shap\")\n",
        "    else:\n",
        "        print(\"⚠️  Model not available for SHAP analysis\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 7: Generate Predictions for Future Games\n",
        "\n",
        "Function to make predictions on new games.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def predict_future_games(future_games_df, historical_games_df, model, feature_names, elo=None):\n",
        "    \"\"\"\n",
        "    Predict residuals for future games\n",
        "    Requires: future_games_df with at least: date, home_team_id, away_team_id, closing_spread\n",
        "    \"\"\"\n",
        "    # Combine historical + future for feature calculation\n",
        "    combined = pd.concat([historical_games_df, future_games_df], ignore_index=True)\n",
        "    combined = combined.sort_values('date').reset_index(drop=True)\n",
        "    \n",
        "    # Build features (this will use historical data for rolling features)\n",
        "    combined_features = build_features(combined, elo=elo, include_spread=True)\n",
        "    \n",
        "    # Extract only future games\n",
        "    future_dates = set(future_games_df['date'])\n",
        "    future_features = combined_features[combined_features['date'].isin(future_dates)].copy()\n",
        "    \n",
        "    if len(future_features) == 0:\n",
        "        return pd.DataFrame()\n",
        "    \n",
        "    # Prepare features\n",
        "    X_future, _, _, meta_future = prepare_model_data(future_features, target='residual')\n",
        "    \n",
        "    if X_future is None:\n",
        "        return pd.DataFrame()\n",
        "    \n",
        "    # Predict\n",
        "    pred_residual = model.predict(X_future, num_iteration=model.best_iteration)\n",
        "    pred_margin = pred_residual + future_features['closing_spread'].values\n",
        "    \n",
        "    # Create predictions DataFrame\n",
        "    predictions = pd.DataFrame({\n",
        "        'date': future_features['date'].values,\n",
        "        'home_team': future_features['home_team_name'].values,\n",
        "        'away_team': future_features['away_team_name'].values,\n",
        "        'closing_spread': future_features['closing_spread'].values,\n",
        "        'predicted_residual': pred_residual,\n",
        "        'predicted_margin': pred_margin,\n",
        "        'predicted_home_cover': (pred_residual > 0).astype(int),\n",
        "        'confidence': np.abs(pred_residual)  # Higher absolute residual = more confident\n",
        "    })\n",
        "    \n",
        "    return predictions.sort_values('date')\n",
        "\n",
        "print(\"✓ Prediction function defined\")\n",
        "print(\"\\nTo use:\")\n",
        "print(\"  predictions = predict_future_games(future_games, features_df, final_lgb_model, feature_names)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 8: Save Models & Export Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save models and feature names\n",
        "import os\n",
        "\n",
        "os.makedirs('models', exist_ok=True)\n",
        "os.makedirs('data/processed', exist_ok=True)\n",
        "\n",
        "if final_lgb_model is not None:\n",
        "    # Save LightGBM model\n",
        "    final_lgb_model.save_model('models/lgb_spread_model.txt')\n",
        "    print(\"✓ Saved LightGBM model to models/lgb_spread_model.txt\")\n",
        "    \n",
        "    # Save feature names\n",
        "    with open('models/feature_names.txt', 'w') as f:\n",
        "        f.write('\\n'.join(feature_names))\n",
        "    print(\"✓ Saved feature names to models/feature_names.txt\")\n",
        "    \n",
        "    # Save feature importance\n",
        "    if len(feature_importance_df) > 0:\n",
        "        feature_importance_df.to_csv('models/feature_importance.csv', index=False)\n",
        "        print(\"✓ Saved feature importance to models/feature_importance.csv\")\n",
        "\n",
        "# Save processed features\n",
        "if len(features_df) > 0:\n",
        "    features_df.to_csv('data/processed/features_with_targets.csv', index=False)\n",
        "    print(\"✓ Saved processed features to data/processed/features_with_targets.csv\")\n",
        "\n",
        "# Save backtest results\n",
        "if len(backtest_preds) > 0:\n",
        "    backtest_preds.to_csv('data/processed/backtest_predictions.csv', index=False)\n",
        "    print(\"✓ Saved backtest predictions to data/processed/backtest_predictions.csv\")\n",
        "\n",
        "print(\"\\n✓ All models and data saved successfully\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 9: Production Deployment Code\n",
        "\n",
        "Example code for deploying the model in production (FastAPI endpoint, scheduled jobs, etc.)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example: Load model and make predictions (for production use)\n",
        "# See production_predict.py example below:\n",
        "\n",
        "# production_predict.py\n",
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "# import lightgbm as lgb\n",
        "# from datetime import datetime\n",
        "# \n",
        "# def load_production_model():\n",
        "#     model = lgb.Booster(model_file='models/lgb_spread_model.txt')\n",
        "#     with open('models/feature_names.txt', 'r') as f:\n",
        "#         feature_names = [line.strip() for line in f.readlines()]\n",
        "#     return model, feature_names\n",
        "# \n",
        "# def predict_game(home_team_id, away_team_id, closing_spread, historical_data):\n",
        "#     # Load model\n",
        "#     model, feature_names = load_production_model()\n",
        "#     \n",
        "#     # Build features for this game (using historical_data)\n",
        "#     # ... (use build_features function)\n",
        "#     \n",
        "#     # Predict\n",
        "#     # pred_residual = model.predict(X_new)\n",
        "#     # pred_margin = pred_residual + closing_spread\n",
        "#     \n",
        "#     return pred_margin, pred_residual\n",
        "\n",
        "# Example FastAPI endpoint:\n",
        "# from fastapi import FastAPI\n",
        "# from pydantic import BaseModel\n",
        "# \n",
        "# app = FastAPI()\n",
        "# \n",
        "# class GamePrediction(BaseModel):\n",
        "#     home_team_id: str\n",
        "#     away_team_id: str\n",
        "#     closing_spread: float\n",
        "#     date: str\n",
        "# \n",
        "# @app.post(\"/predict\")\n",
        "# def predict(game: GamePrediction):\n",
        "#     # Load model, build features, predict\n",
        "#     pred_margin, pred_residual = predict_game(\n",
        "#         game.home_team_id, \n",
        "#         game.away_team_id, \n",
        "#         game.closing_spread,\n",
        "#         load_historical_data()\n",
        "#     )\n",
        "#     return {\n",
        "#         \"predicted_margin\": pred_margin,\n",
        "#         \"predicted_residual\": pred_residual,\n",
        "#         \"home_covers\": pred_residual > 0\n",
        "#     }\n",
        "\n",
        "print(\"✓ Production deployment code template provided\")\n",
        "print(\"\\nSee comments above for FastAPI example\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 10: Monitoring & Model Drift Detection\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def monitor_model_performance(predictions_df, actual_results_df, baseline_mae=None):\n",
        "    \"\"\"\n",
        "    Monitor model performance over time\n",
        "    Detects model drift and performance degradation\n",
        "    \"\"\"\n",
        "    # Merge predictions with actual results\n",
        "    merged = predictions_df.merge(\n",
        "        actual_results_df[['date', 'home_team', 'away_team', 'margin', 'residual']],\n",
        "        on=['date', 'home_team', 'away_team'],\n",
        "        how='inner'\n",
        "    )\n",
        "    \n",
        "    if len(merged) == 0:\n",
        "        return None\n",
        "    \n",
        "    # Calculate metrics by time window\n",
        "    merged['date'] = pd.to_datetime(merged['date'])\n",
        "    merged = merged.sort_values('date')\n",
        "    \n",
        "    # Rolling performance (last 20 games)\n",
        "    window_size = 20\n",
        "    metrics = []\n",
        "    \n",
        "    for i in range(window_size, len(merged)):\n",
        "        window = merged.iloc[i-window_size:i]\n",
        "        \n",
        "        mae = mean_absolute_error(window['residual'], window['predicted_residual'])\n",
        "        cover_acc = (window['predicted_home_cover'] == (window['residual'] > 0)).mean()\n",
        "        \n",
        "        metrics.append({\n",
        "            'date': window.iloc[-1]['date'],\n",
        "            'mae': mae,\n",
        "            'cover_accuracy': cover_acc,\n",
        "            'n_games': len(window)\n",
        "        })\n",
        "    \n",
        "    metrics_df = pd.DataFrame(metrics)\n",
        "    \n",
        "    # Detect drift (MAE increases significantly)\n",
        "    if baseline_mae and len(metrics_df) > 0:\n",
        "        current_mae = metrics_df['mae'].iloc[-10:].mean()\n",
        "        drift_threshold = baseline_mae * 1.15  # 15% increase\n",
        "        \n",
        "        if current_mae > drift_threshold:\n",
        "            print(f\"⚠️  MODEL DRIFT DETECTED!\")\n",
        "            print(f\"   Baseline MAE: {baseline_mae:.3f}\")\n",
        "            print(f\"   Current MAE: {current_mae:.3f}\")\n",
        "            print(f\"   Increase: {(current_mae/baseline_mae - 1)*100:.1f}%\")\n",
        "            print(f\"   Recommendation: Retrain model\")\n",
        "        else:\n",
        "            print(f\"✓ Model performance stable (MAE: {current_mae:.3f})\")\n",
        "    \n",
        "    return metrics_df\n",
        "\n",
        "print(\"✓ Model monitoring function defined\")\n",
        "print(\"\\nUse this to track model performance over time and detect drift\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary & Next Steps\n",
        "\n",
        "### What We've Built:\n",
        "1. ✅ **Feature Engineering Pipeline**: ELO ratings, rolling stats, rest days, temporal features\n",
        "2. ✅ **Multiple Models**: Baseline, Linear (Ridge), LightGBM\n",
        "3. ✅ **Time-Series Cross-Validation**: Proper walk-forward validation\n",
        "4. ✅ **Backtesting Framework**: Simulates real-world deployment\n",
        "5. ✅ **Model Interpretation**: Feature importance, SHAP support\n",
        "6. ✅ **Production-Ready Code**: Model saving, prediction functions, monitoring\n",
        "\n",
        "### Key Features:\n",
        "- **Target**: Predicts `residual = margin - closing_spread` (betting edge)\n",
        "- **No Data Leakage**: Features computed only from past games\n",
        "- **Time-Aware**: Proper time-series validation prevents overfitting\n",
        "- **Betting Metrics**: Cover accuracy, average edge, MAE on margin\n",
        "\n",
        "### To Improve:\n",
        "1. **Add Injury Data**: Integrate player availability/minutes lost\n",
        "2. **Add Travel Data**: Calculate distance/time zones between cities\n",
        "3. **Add Market Data**: Opening spreads, line movement, public betting %\n",
        "4. **Advanced Features**: Play-by-play, lineup-based metrics, clutch performance\n",
        "5. **Probabilistic Predictions**: Quantile regression for uncertainty\n",
        "6. **Ensemble Models**: Stack ELO + LightGBM + Neural Network\n",
        "\n",
        "### Deployment Checklist:\n",
        "- [ ] Set up daily data collection job\n",
        "- [ ] Automate feature calculation pipeline\n",
        "- [ ] Schedule weekly model retraining\n",
        "- [ ] Deploy prediction API (FastAPI/Flask)\n",
        "- [ ] Set up monitoring dashboard\n",
        "- [ ] Implement alerting for model drift\n",
        "- [ ] Backtest on historical data before live deployment\n",
        "\n",
        "### Important Notes:\n",
        "- ⚠️ **Gambling Laws**: Be aware of local regulations\n",
        "- ⚠️ **Vigorish**: Account for bookmaker house edge (~4.5% on spreads)\n",
        "- ⚠️ **Sample Size**: Early season predictions have higher variance\n",
        "- ⚠️ **Data Quality**: Accurate injury/line data is critical\n",
        "\n",
        "### Files Generated:\n",
        "- `models/lgb_spread_model.txt` - Trained LightGBM model\n",
        "- `models/feature_names.txt` - Feature list\n",
        "- `models/feature_importance.csv` - Feature rankings\n",
        "- `data/processed/features_with_targets.csv` - Full feature dataset\n",
        "- `data/processed/backtest_predictions.csv` - Backtest results\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Appendix: Requirements File\n",
        "\n",
        "Create a `requirements.txt` file with:\n",
        "```\n",
        "pandas>=1.5.0\n",
        "numpy>=1.23.0\n",
        "scikit-learn>=1.2.0\n",
        "lightgbm>=3.3.0\n",
        "matplotlib>=3.6.0\n",
        "seaborn>=0.12.0\n",
        "shap>=0.41.0\n",
        "joblib>=1.2.0\n",
        "requests>=2.28.0\n",
        "```\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
